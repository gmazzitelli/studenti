{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO6Aeil0u5wa4aLNM5qykJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gmazzitelli/studenti/blob/master/CpuGpu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OSSYS=!uname -a | awk '{print $1}'\n",
        "# \"Darwin\" o \"Linux\"\n",
        "if OSSYS[0]==\"Linux\":\n",
        "  cpu=!lscpu\n",
        "  gpu=!nvidia-smi\n",
        "if OSSYS[0]==\"Darwin\":\n",
        "  cpu=!sysctl -a machdep.cpu\n",
        "  gpu=!ioreg -l | grep num_cores\n",
        "print(OSSYS)\n",
        "print(cpu)\n",
        "print(gpu)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaQO2KZMMVd2",
        "outputId": "36c22c59-1e10-4ab0-b0ad-92b988e00c8c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Linux']\n",
            "['Architecture:        x86_64', 'CPU op-mode(s):      32-bit, 64-bit', 'Byte Order:          Little Endian', 'CPU(s):              2', 'On-line CPU(s) list: 0,1', 'Thread(s) per core:  2', 'Core(s) per socket:  1', 'Socket(s):           1', 'NUMA node(s):        1', 'Vendor ID:           GenuineIntel', 'CPU family:          6', 'Model:               79', 'Model name:          Intel(R) Xeon(R) CPU @ 2.20GHz', 'Stepping:            0', 'CPU MHz:             2199.998', 'BogoMIPS:            4399.99', 'Hypervisor vendor:   KVM', 'Virtualization type: full', 'L1d cache:           32K', 'L1i cache:           32K', 'L2 cache:            256K', 'L3 cache:            56320K', 'NUMA node0 CPU(s):   0,1', 'Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities']\n",
            "['Thu Dec 15 09:32:43 2022       ', '+-----------------------------------------------------------------------------+', '| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |', '|-------------------------------+----------------------+----------------------+', '| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |', '| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |', '|                               |                      |               MIG M. |', '|===============================+======================+======================|', '|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |', '| N/A   46C    P0    26W /  70W |      0MiB / 15109MiB |      0%      Default |', '|                               |                      |                  N/A |', '+-------------------------------+----------------------+----------------------+', '                                                                               ', '+-----------------------------------------------------------------------------+', '| Processes:                                                                  |', '|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |', '|        ID   ID                                                   Usage      |', '|=============================================================================|', '|  No running processes found                                                 |', '+-----------------------------------------------------------------------------+']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoJ4-KokwUQa",
        "outputId": "2205d526-c1eb-4351-fe75-6e66ac14727f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up; see: https://stackoverflow.com/a/45067900\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch x height x width x channel). Sum of ten runs.')\n",
        "print('CPU (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('GPU (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NC1wZLZwVEm",
        "outputId": "45b381cb-030f-40a2-b5da-3af67911412c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch x height x width x channel). Sum of ten runs.\n",
            "CPU (s):\n",
            "3.085042453000028\n",
            "GPU (s):\n",
            "0.0375277779999692\n",
            "GPU speedup over CPU: 82x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4NOIbV6k1x6H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}